{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folderName = 'dl_data_raw'\n",
    "# mat = scipy.io.loadmat(folderName+'/Test/normal.mat')\n",
    "# test_normal_data, test_normal_label = mat['normal_data'], mat['normal_label']\n",
    "\n",
    "# mat = scipy.io.loadmat(folderName+'/Test/sick.mat')\n",
    "# test_sick_data, test_sick_label = mat['sick_data'], mat['sick_label']\n",
    "\n",
    "# mat = scipy.io.loadmat(folderName+'/Train/normal.mat')\n",
    "# train_normal_data, train_normal_label = mat['normal_data'], mat['normal_label']\n",
    "\n",
    "# mat = scipy.io.loadmat(folderName+'/Train/sick.mat')\n",
    "# train_sick_data, train_sick_label = mat['sick_data'], mat['sick_label']\n",
    "\n",
    "# # Divide the testing set into 50-50 testing-validation set\n",
    "# t_normal_indices = list(range(len(test_normal_label)))\n",
    "# test_normal_indices, valid_normal_indices = train_test_split(t_normal_indices, test_size=0.5)\n",
    "\n",
    "# t_sick_indices = list(range(len(test_sick_label)))\n",
    "# test_sick_indices, valid_sick_indices = train_test_split(t_sick_indices, test_size=0.5)\n",
    "\n",
    "# t_normal_data, t_normal_label = test_normal_data[test_normal_indices,:,:], test_normal_label[test_normal_indices]\n",
    "# valid_normal_data, valid_normal_label = test_normal_data[valid_normal_indices,:,:], test_normal_label[valid_normal_indices]\n",
    "\n",
    "# t_sick_data, t_sick_label = test_sick_data[test_sick_indices,:,:], test_sick_label[test_sick_indices]\n",
    "# valid_sick_data, valid_sick_label = test_sick_data[valid_sick_indices,:,:], test_sick_label[valid_sick_indices]\n",
    "\n",
    "\n",
    "# # Concatinate the validation, testing and training sick-normal data\n",
    "# data_set = np.concatenate((test_normal_data, train_normal_data, test_sick_data, train_sick_data), axis=0)\n",
    "# label_set = np.concatenate((test_normal_label, train_normal_label, test_sick_label, train_sick_label), axis=0)\n",
    "\n",
    "# train_data_set = np.concatenate((train_normal_data, train_sick_data), axis=0)\n",
    "# train_label_set = np.concatenate((train_normal_label, train_sick_label), axis=0)\n",
    "\n",
    "# test_data_set = np.concatenate((t_normal_data, t_sick_data), axis=0)\n",
    "# test_label_set = np.concatenate((t_normal_label, t_sick_label), axis=0)\n",
    "\n",
    "# valid_data_set = np.concatenate((valid_normal_data, valid_sick_data), axis=0)\n",
    "# valid_label_set = np.concatenate((valid_normal_label, valid_sick_label), axis=0)\n",
    "\n",
    "# print(\"Shapes\")\n",
    "# print(\"Train Data: \"+str(train_data_set.shape)+\" Train Lable: \"+str(train_label_set.shape))\n",
    "# print(\"Test Data: \"+str(test_data_set.shape)+\" Test Lable: \"+str(test_label_set.shape))\n",
    "# print(\"Valid Data: \"+str(valid_data_set.shape)+\" Train Lable: \"+str(valid_label_set.shape))\n",
    "\n",
    "# print(\"-------- INFORMATION ON THE DATA ---------\")\n",
    "# print(\"Shapes\")\n",
    "# print(\"Train Data: \"+str(train_data_set.shape)+\" Train Lable: \"+str(train_label_set.shape))\n",
    "# print(\"Test Data: \"+str(test_data_set.shape)+\" Test Lable: \"+str(test_label_set.shape))\n",
    "# print(\"Valid Data: \"+str(valid_data_set.shape)+\" Train Lable: \"+str(valid_label_set.shape))\n",
    "\n",
    "# print(\"***********************************************************************************\")\n",
    "\n",
    "# print(\"Number of NANs in the data\")\n",
    "# print(\"Train Data: \"+str(np.sum(np.isnan(train_data_set)))+\" Train Lable: \"+str(np.sum(np.isnan(train_label_set))))\n",
    "# print(\"Test Data: \"+str(np.sum(np.isnan(test_data_set)))+\" Test Lable: \"+str(np.sum(np.isnan(test_label_set))))\n",
    "# print(\"Valid Data: \"+str(np.sum(np.isnan(valid_data_set)))+\" Train Lable: \"+str(np.sum(np.isnan(valid_label_set))))\n",
    "\n",
    "# print(\"***********************************************************************************\")\n",
    "\n",
    "# print(\"Some stats on the data\")\n",
    "# print(\"Number of label classes: \" + str(len(set(tuple(row) for row in label_set))))\n",
    "\n",
    "# print(\"**************************************** FULL DATASET *******************************************\")\n",
    "\n",
    "# print(\"Maximum Value in Data Set: \" + str(np.amax(data_set)))\n",
    "# print(\"Minimum Value in Data Set: \" + str(np.amin(data_set)))\n",
    "# print(\"Mean Value in Data Set: \" + str(np.mean(data_set)))\n",
    "# print(\"Standard Daviation in Data Set: \" + str(np.std(data_set)))\n",
    "\n",
    "# print(\"************************************* TRAINING DATASET **********************************************\")\n",
    "\n",
    "# print(\"Maximum Value in Training Set: \" + str(np.amax(train_data_set)))\n",
    "# print(\"Minimum Value in Data Set: \" + str(np.amin(train_data_set)))\n",
    "# print(\"Mean Value in Data Set: \" + str(np.mean(train_data_set)))\n",
    "# print(\"Standard Daviation in Data Set: \" + str(np.std(train_data_set)))\n",
    "\n",
    "# print(\"*************************************** TESTING DATASET ********************************************\")\n",
    "\n",
    "# print(\"Maximum Value in Testing Set: \" + str(np.amax(test_data_set)))\n",
    "# print(\"Minimum Value in Data Set: \" + str(np.amin(test_data_set)))\n",
    "# print(\"Mean Value in Data Set: \" + str(np.mean(test_data_set)))\n",
    "# print(\"Standard Daviation in Data Set: \" + str(np.std(test_data_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load traing and testing sets\n",
    "# mat = scipy.io.loadmat('data/normal.mat')\n",
    "# normal_data, normal_label = mat['normal_data'], mat['normal_label']\n",
    "\n",
    "# mat = scipy.io.loadmat('data/sick.mat')\n",
    "# sick_data, sick_label = mat['sick_data'], mat['sick_label']\n",
    "\n",
    "#################################################################################################################################\n",
    "# folderName = 'dl_data_raw'\n",
    "# mat = scipy.io.loadmat(folderName+'/Test/normal.mat')\n",
    "# test_normal_data, test_normal_label = mat['normal_data'], mat['normal_label']\n",
    "\n",
    "# mat = scipy.io.loadmat(folderName+'/Test/sick.mat')\n",
    "# test_sick_data, test_sick_label = mat['sick_data'], mat['sick_label']\n",
    "\n",
    "# mat = scipy.io.loadmat(folderName+'/Train/normal.mat')\n",
    "# train_normal_data, train_normal_label = mat['normal_data'], mat['normal_label']\n",
    "\n",
    "# mat = scipy.io.loadmat(folderName+'/Train/sick.mat')\n",
    "# train_sick_data, train_sick_label = mat['sick_data'], mat['sick_label']\n",
    "\n",
    "# normal_data, normal_label = np.concatenate((test_normal_data, train_normal_data), axis=0), np.concatenate((test_normal_label, train_normal_label), axis=0)\n",
    "# sick_data, sick_label = np.concatenate((test_sick_data,train_sick_data), axis=0), np.concatenate((test_sick_label,train_sick_label), axis=0)\n",
    "\n",
    "# normal_indices = list(range(len(normal_label)))\n",
    "# train_normal_indices, test_normal_indices = train_test_split(normal_indices, test_size=0.2)\n",
    "# test_normal_indices, vlidation_normal_indices = train_test_split(test_normal_indices, test_size=0.5)\n",
    "\n",
    "# sick_indices = list(range(len(sick_label)))\n",
    "# train_sick_indices, test_sick_indices = train_test_split(sick_indices, test_size=0.2)\n",
    "# test_sick_indices, vlidation_sick_indices = train_test_split(test_sick_indices, test_size=0.5)\n",
    "\n",
    "# train_normal_data, train_normal_label = normal_data[train_normal_indices,:,:], normal_label[train_normal_indices]\n",
    "# test_normal_data, test_normal_label = normal_data[test_normal_indices,:,:], normal_label[test_normal_indices]\n",
    "# validation_normal_data, validation_normal_label = normal_data[vlidation_normal_indices,:,:], normal_label[vlidation_normal_indices]\n",
    "\n",
    "# train_sick_data, train_sick_label = sick_data[train_sick_indices,:,:], sick_label[train_sick_indices]\n",
    "# test_sick_data, test_sick_label = sick_data[test_sick_indices,:,:], sick_label[test_sick_indices]\n",
    "# validation_sick_data, validation_sick_label = sick_data[vlidation_sick_indices,:,:], sick_label[vlidation_sick_indices]\n",
    "\n",
    "# data_set = np.concatenate((normal_data, sick_data), axis=0)\n",
    "# label_set = np.concatenate((normal_label, sick_label), axis=0)\n",
    "\n",
    "# train_data_set = np.concatenate((train_normal_data, train_sick_data), axis=0)\n",
    "# train_label_set = np.concatenate((train_normal_label, train_sick_label), axis=0)\n",
    "\n",
    "# test_data_set = np.concatenate((test_normal_data, test_sick_data), axis=0)\n",
    "# test_label_set = np.concatenate((test_normal_label, test_sick_label), axis=0)\n",
    "\n",
    "# valid_data_set = np.concatenate((validation_normal_data, validation_sick_data), axis=0)\n",
    "# valid_label_set = np.concatenate((validation_normal_label, validation_sick_label), axis=0)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
