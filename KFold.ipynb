{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import sys\n",
    "import os, time\n",
    "import torch \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, utils\n",
    "import random, matplotlib\n",
    "import pandas as pd\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "#from torchvision.models.resnet import BasicBlock\n",
    "#import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "import scipy.io\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "sys.path.append('./models/')\n",
    "sys.path.append('./source/')\n",
    "\n",
    "import utils as myUtils\n",
    "from DataTypes import EEGDataset\n",
    "from CNN_1 import Network\n",
    "\n",
    "# Check does your computer support using GPU\n",
    "print(\"GPU_available={}\".format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# EEG_file_types = [2,1,0]\n",
    "EEG_file_types = [3]\n",
    "\n",
    "for EEG_file_type in EEG_file_types:\n",
    "\n",
    "    folder = \"./Results/trial13/1FC_layer/\"\n",
    "\n",
    "    if(EEG_file_type == 0):\n",
    "        mat = scipy.io.loadmat('EEG_samples_raw.mat')\n",
    "        EEG_samples = mat['EEG_samples']\n",
    "        sub_folder = \"Kfold_raw/\"\n",
    "    elif(EEG_file_type == 3):\n",
    "        sub_folder = \"Kfold_noise_pruned/\"\n",
    "    elif(EEG_file_type == 2):\n",
    "        mat = scipy.io.loadmat('EEG_samples_pruned.mat')\n",
    "        EEG_samples = mat['EEG_samples']\n",
    "        sub_folder = \"Kfold_pruned/\"\n",
    "    else:\n",
    "        mat = scipy.io.loadmat('EEG_samples_roi.mat')\n",
    "        EEG_samples = mat['EEG_samples']\n",
    "        sub_folder = \"Kfold_roi/\"\n",
    "\n",
    "    folder = folder + sub_folder\n",
    "    no_participants = 29\n",
    "    train_data_set, train_label_set = [], []\n",
    "    epoches = 150\n",
    "\n",
    "    for partic_id in range(0,no_participants):\n",
    "        fileName = \"Subject_\"+str(partic_id+1)+\"_Results.txt\"\n",
    "        testFileName = \"Test_Results.txt\"\n",
    "        path = folder+fileName\n",
    "        test_path = folder+testFileName\n",
    "\n",
    "        # Spilt the data into training and testing sets \n",
    "        if(EEG_file_type == 3):\n",
    "            full_data, train_data, test_data = myUtils.generateTrainTestByFile('EEG_samples_noise_pruned.mat', partic_id, normalize = True)\n",
    "        else:\n",
    "            full_data, train_data, test_data = myUtils.generateTrainTest(EEG_samples, partic_id, normalize = True)\n",
    "\n",
    "        # Save information concerning the data to file\n",
    "        myUtils.writeStatsToFile(full_data, train_data, test_data, path)\n",
    "\n",
    "        # Create a torch data loader for both the training and testing sets\n",
    "        train_loader = myUtils.generateTorchLoaders(train_data[0], train_data[1], EEGDataset)\n",
    "        test_loader = myUtils.generateTorchLoaders(test_data[0], test_data[1], EEGDataset)\n",
    "\n",
    "        # Create Instance of CNN model\n",
    "        net = Network(num_classes=2)\n",
    "\n",
    "        # Train the model\n",
    "        print(\"Training on-going for participant \"+str(partic_id+1))\n",
    "        net = myUtils.train(net, train_loader, test_loader, epoches, path)\n",
    "\n",
    "        #Test the model\n",
    "        acc_test = myUtils.eval(net, test_loader, test_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'EEG_samples_noise_pruned.mat'\n",
    "variable_name = 'EEG_samples'\n",
    "\n",
    "with h5py.File(file_name, 'r') as f:\n",
    "    #print(\"Keys: %s\" % f.keys())\n",
    "    #print(f['EEG_samples'].keys())\n",
    "    #print(f['EEG_samples']['data'].shape[0])\n",
    "    print(f['EEG_samples']['data'][2])\n",
    "    ref = np.array(f['EEG_samples']['data'][0][()])\n",
    "\n",
    "    # Dereference the object reference\n",
    "    group = f[ref.item()]\n",
    "    print(group)\n",
    "    print(np.array(group['non_sick'][()]).shape)\n",
    "    print(np.array(group['non_sick'][()]).transpose(2,1,0).shape)\n",
    "\n",
    "    # Iterate through the group members and access the datasets\n",
    "    # for key in group.keys():\n",
    "    #     dataset = group[key]\n",
    "\n",
    "    #     # Access the data and convert it to a NumPy array\n",
    "    #     data_np = np.array(dataset[()])\n",
    "    #     print(f\"Dataset '{key}':\")\n",
    "    #     print(data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data, train_data, test_data = myUtils.generateTrainTestByFile('EEG_samples_noise_pruned.mat', 2, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-------- INFORMATION ON THE DATA ---------\\n\")\n",
    "print(\"Shapes\\n\")\n",
    "print(\"Train Data: \"+str(train_data[0].shape)+\" Train Lable: \"+str(train_data[1].shape)+\"\\n\")\n",
    "print(\"Test Data: \"+str(test_data[0].shape)+\" Test Lable: \"+str(test_data[1].shape)+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
