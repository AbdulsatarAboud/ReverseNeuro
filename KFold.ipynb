{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU_available=True\n"
     ]
    }
   ],
   "source": [
    "# import necessary packages\n",
    "import sys\n",
    "import os, time\n",
    "import torch \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, utils\n",
    "import random, matplotlib\n",
    "import pandas as pd\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "#from torchvision.models.resnet import BasicBlock\n",
    "#import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "import scipy.io\n",
    "import h5py\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "sys.path.append('./models/')\n",
    "sys.path.append('./source/')\n",
    "\n",
    "import utils as myUtils\n",
    "from DataTypes import EEGDataset\n",
    "from CNN_1 import Network\n",
    "\n",
    "# Check does your computer support using GPU\n",
    "print(\"GPU_available={}\".format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on-going for participant 29\n",
      "Cuda is Avaliable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdulsatar\\Documents\\UBICOMP\\Thesis Work\\ReverseNeuro\\./models\\CNN_1.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax8(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, lr: 0.010000, accuracy: 0.504481, loss: 0.691296, valid accuracy: 0.671806\n",
      "epoch: 1, lr: 0.010000, accuracy: 0.531605, loss: 0.690368, valid accuracy: 0.590308\n",
      "epoch: 2, lr: 0.010000, accuracy: 0.550568, loss: 0.684376, valid accuracy: 0.592511\n",
      "epoch: 3, lr: 0.010000, accuracy: 0.561610, loss: 0.680817, valid accuracy: 0.958150\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining on-going for participant \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(partic_id\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m---> 62\u001b[0m net \u001b[39m=\u001b[39m myUtils\u001b[39m.\u001b[39;49mtrain(net, train_loader, test_loader, epoches, path)\n\u001b[0;32m     64\u001b[0m state_dict \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39mstate_dict()\n\u001b[0;32m     65\u001b[0m torch\u001b[39m.\u001b[39msave(state_dict, \u001b[39m'\u001b[39m\u001b[39mtrained_models/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mtrial\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39msub_folder\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39mArch\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(partic_id\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.pth\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Abdulsatar\\Documents\\UBICOMP\\Thesis Work\\ReverseNeuro\\./source\\utils.py:381\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net, train_loader, valid_loader, epoches, file_name)\u001b[0m\n\u001b[0;32m    378\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mLongTensor)\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m use_cuda:\n\u001b[1;32m--> 381\u001b[0m     images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39;49mcuda()\n\u001b[0;32m    382\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m    384\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This code is for training multiple models using Leave One Out (LOU)\n",
    "\n",
    "# EEG_file_types = [2,1,0]\n",
    "EEG_file_types = [10]\n",
    "\n",
    "for EEG_file_type in EEG_file_types:\n",
    "\n",
    "    trial = \"trial21\"\n",
    "    folder = \"./Results/\"+trial+\"/1FC_layer/\"\n",
    "\n",
    "    if(EEG_file_type == 0):\n",
    "        mat = scipy.io.loadmat('EEG_samples_raw.mat')\n",
    "        EEG_samples = mat['EEG_samples']\n",
    "        sub_folder = \"Kfold_raw/\"\n",
    "    elif(EEG_file_type == 3):\n",
    "        sub_folder = \"Kfold_noise_pruned/\"\n",
    "    elif(EEG_file_type == 2):\n",
    "        mat = scipy.io.loadmat('EEG_samples_pruned.mat')\n",
    "        EEG_samples = mat['EEG_samples']\n",
    "        sub_folder = \"Kfold_pruned/\"\n",
    "    else:\n",
    "        mat = scipy.io.loadmat('EEG_samples_roi.mat')\n",
    "        EEG_samples = mat['EEG_samples']\n",
    "        sub_folder = \"Kfold_roi/\"\n",
    "\n",
    "    folder = folder + sub_folder\n",
    "    no_participants = 29\n",
    "    train_data_set, train_label_set = [], []\n",
    "    epoches = 550\n",
    "\n",
    "    for partic_id in range(27,no_participants):\n",
    "        fileName = \"Subject_\"+str(partic_id+1)+\"_Results.txt\"\n",
    "        testFileName = \"Test_Results.txt\"\n",
    "        path = folder+fileName\n",
    "        test_path = folder+testFileName\n",
    "\n",
    "        # Spilt the data into training and testing sets \n",
    "        if(EEG_file_type == 3):\n",
    "            full_data, train_data, test_data = myUtils.generateTrainTestByFile('EEG_samples_noise_pruned.mat', partic_id, normalize = True, LOU = False)\n",
    "        else:\n",
    "            full_data, train_data, test_data = myUtils.generateTrainTest(EEG_samples, partic_id, normalize = False, LOU = True)\n",
    "\n",
    "        # Save information concerning the data to file\n",
    "        myUtils.writeStatsToFile(full_data, train_data, test_data, path)\n",
    "\n",
    "        # Create a torch data loader for both the training and testing sets\n",
    "        train_loader = myUtils.generateTorchLoaders(train_data[0], train_data[1], EEGDataset)\n",
    "        test_loader = myUtils.generateTorchLoaders(test_data[0], test_data[1], EEGDataset)\n",
    "\n",
    "        # Free up memory space\n",
    "        del full_data\n",
    "        del train_data\n",
    "        del test_data\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "        # Create Instance of CNN model\n",
    "        net = Network(num_classes=2)\n",
    "\n",
    "        # Train the model\n",
    "        print(\"Training on-going for participant \"+str(partic_id+1))\n",
    "        net = myUtils.train(net, train_loader, test_loader, epoches, path)\n",
    "\n",
    "        state_dict = net.state_dict()\n",
    "        torch.save(state_dict, 'trained_models/'+trial+'/'+sub_folder+'Arch'+str(partic_id+1)+'.pth')\n",
    "\n",
    "        #Test the model\n",
    "        acc_test = myUtils.eval(net, test_loader, test_path)\n",
    "\n",
    "        # Free up memory space\n",
    "        del train_loader\n",
    "        del test_loader\n",
    "        del net\n",
    "        gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is fot training a single model\n",
    "\n",
    "# EEG_file_types = [2,1,0]\n",
    "EEG_file_types = [2]\n",
    "\n",
    "for EEG_file_type in EEG_file_types:\n",
    "\n",
    "    trial = \"trial24\"\n",
    "    folder = \"./Results/\"+trial+\"/1FC_layer/\"\n",
    "\n",
    "    if(EEG_file_type == 0):\n",
    "        mat = scipy.io.loadmat('EEG_samples_raw.mat')\n",
    "        EEG_samples = mat['EEG_samples']\n",
    "        sub_folder = \"Kfold_raw/\"\n",
    "    elif(EEG_file_type == 3):\n",
    "        sub_folder = \"Kfold_noise_pruned/\"\n",
    "    elif(EEG_file_type == 2):\n",
    "        mat = scipy.io.loadmat('EEG_samples_pruned.mat')\n",
    "        EEG_samples = mat['EEG_samples']\n",
    "        sub_folder = \"Kfold_pruned/\"\n",
    "    else:\n",
    "        mat = scipy.io.loadmat('EEG_samples_roi.mat')\n",
    "        EEG_samples = mat['EEG_samples']\n",
    "        sub_folder = \"Kfold_roi/\"\n",
    "\n",
    "    folder = folder + sub_folder\n",
    "    no_participants = 29\n",
    "    train_data_set, train_label_set = [], []\n",
    "    epoches = 550\n",
    "\n",
    "   \n",
    "    fileName = \"Results.txt\"\n",
    "    testFileName = \"Test_Results.txt\"\n",
    "    path = folder+fileName\n",
    "    test_path = folder+testFileName\n",
    "\n",
    "\n",
    "    full_data, train_data, test_data = myUtils.generateTrainTest(EEG_samples, 1, normalize = True, LOU = False)\n",
    "\n",
    "    # Save information concerning the data to file\n",
    "    myUtils.writeStatsToFile(full_data, train_data, test_data, path)\n",
    "\n",
    "    # Create a torch data loader for both the training and testing sets\n",
    "    train_loader = myUtils.generateTorchLoaders(train_data[0], train_data[1], EEGDataset)\n",
    "    test_loader = myUtils.generateTorchLoaders(test_data[0], test_data[1], EEGDataset)\n",
    "\n",
    "    # Free up memory space\n",
    "    del full_data\n",
    "    del train_data\n",
    "    del test_data\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    # Create Instance of CNN model\n",
    "    net = Network(num_classes=2)\n",
    "\n",
    "    # Train the model\n",
    "    print(\"Training on-going for participant \")\n",
    "    net = myUtils.train(net, train_loader, test_loader, epoches, path)\n",
    "\n",
    "    state_dict = net.state_dict()\n",
    "    torch.save(state_dict, 'trained_models/'+trial+'/Arch.pth')\n",
    "\n",
    "    #Test the model\n",
    "    acc_test = myUtils.eval(net, test_loader, test_path)\n",
    "\n",
    "    # Free up memory space\n",
    "    del train_loader\n",
    "    del test_loader\n",
    "    del net\n",
    "    gc.collect()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ae30fb4a0ad61ae157becce4826a5633e65132e4bb754ebc68ff1c21d960e68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
